{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OST Writing Assessment: Feature Selection Analysis\n",
    "\n",
    "VIF-guided elastic net feature selection for predicting writing quality.\n",
    "\n",
    "**Reproducibility**: Results may vary slightly (±0.01 R²) due to CV fold assignments. Use `random_state=42`.\n",
    "\n",
    "**Key Parameters**:\n",
    "- VIF threshold: 10\n",
    "- Bootstrap: 1,000 iterations, selection threshold |β| > 0.05\n",
    "- Elastic Net: L1 ratios [0.1, 0.3, 0.5, 0.7, 0.9], 10-fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import ElasticNetCV, ElasticNet\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Writing_Assessment_Cleaned_Dataset_Tool_Specify.csv')\n",
    "target = 'Writing_Quality_Sum_Score'\n",
    "ost_features = [col for col in df.columns if col.startswith('OST_')]\n",
    "\n",
    "print(f\"N = {len(df)}, OST features = {len(ost_features)}\")\n",
    "print(f\"Target: M = {df[target].mean():.2f}, SD = {df[target].std():.2f}\")\n",
    "print(f\"Native (0): n={sum(df['Primary_Language']==0)}, Non-native (1): n={sum(df['Primary_Language']==1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VIF Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_vif(X):\n",
    "    X_scaled = StandardScaler().fit_transform(X)\n",
    "    vif = []\n",
    "    for i in range(X_scaled.shape[1]):\n",
    "        try:\n",
    "            v = variance_inflation_factor(X_scaled, i)\n",
    "            v = v if np.isfinite(v) and v < 1e10 else np.inf\n",
    "        except:\n",
    "            v = np.inf\n",
    "        vif.append({'feature': X.columns[i], 'VIF': v})\n",
    "    return pd.DataFrame(vif).sort_values('VIF', ascending=False)\n",
    "\n",
    "def iterative_vif_removal(df, features, threshold=10):\n",
    "    current = features.copy()\n",
    "    removed = []\n",
    "    while True:\n",
    "        X = df[current].dropna()\n",
    "        if X.shape[1] < 2:\n",
    "            break\n",
    "        vif_df = calculate_vif(X)\n",
    "        if vif_df.iloc[0]['VIF'] <= threshold:\n",
    "            break\n",
    "        feat = vif_df.iloc[0]['feature']\n",
    "        removed.append((feat, vif_df.iloc[0]['VIF']))\n",
    "        current.remove(feat)\n",
    "        print(f\"  Removed: {feat} (VIF={vif_df.iloc[0]['VIF']:.1f})\")\n",
    "    return current, removed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[target]\n",
    "\n",
    "# Top 15 by |correlation|\n",
    "correlations = [(f, abs(df[f].corr(y)), df[f].corr(y)) for f in ost_features]\n",
    "correlations.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(\"Top 15 features by |r|:\")\n",
    "for i, (f, _, r) in enumerate(correlations[:15], 1):\n",
    "    print(f\"  {i:2d}. {f:40s} r={r:+.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_15 = [f for f, _, _ in correlations[:15]]\n",
    "final_features, removed = iterative_vif_removal(df, top_15.copy(), threshold=10)\n",
    "print(f\"\\nFinal: {len(final_features)} features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elastic Net Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[final_features]\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "model = ElasticNetCV(\n",
    "    l1_ratio=[0.1, 0.3, 0.5, 0.7, 0.9],\n",
    "    alphas=np.logspace(-3, 1, 30),\n",
    "    cv=10, max_iter=5000, random_state=42\n",
    ")\n",
    "model.fit(X_scaled, y)\n",
    "\n",
    "y_pred = model.predict(X_scaled)\n",
    "r2 = r2_score(y, y_pred)\n",
    "n, p = len(y), len(final_features)\n",
    "adj_r2 = 1 - (1 - r2) * (n - 1) / (n - p - 1)\n",
    "mse = mean_squared_error(y, y_pred)\n",
    "aic = n * np.log(mse) + 2 * p\n",
    "bic = n * np.log(mse) + p * np.log(n)\n",
    "\n",
    "print(f\"N={n}, Features={p}\")\n",
    "print(f\"R²={r2:.3f}, Adj R²={adj_r2:.3f}\")\n",
    "print(f\"AIC={aic:.1f}, BIC={bic:.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VIF check\n",
    "vif_final = calculate_vif(X)\n",
    "print(f\"VIF: mean={vif_final['VIF'].mean():.2f}, max={vif_final['VIF'].max():.2f}\")\n",
    "\n",
    "# Coefficients\n",
    "print(\"\\nCoefficients:\")\n",
    "coef_df = pd.DataFrame({'feature': final_features, 'coef': model.coef_})\n",
    "coef_df = coef_df.sort_values('coef', key=abs, ascending=False)\n",
    "for _, row in coef_df.iterrows():\n",
    "    print(f\"  {row['feature']:45s} β={row['coef']:+.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstrap Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selection threshold |β| > 0.05 excludes coefficients with negligible practical significance\n",
    "THRESH = 0.05\n",
    "n_boot = 1000\n",
    "\n",
    "boot_r2 = []\n",
    "selection_count = {f: 0 for f in final_features}\n",
    "\n",
    "for i in range(n_boot):\n",
    "    idx = np.random.choice(len(y), len(y), replace=True)\n",
    "    m = ElasticNet(alpha=model.alpha_, l1_ratio=model.l1_ratio_, max_iter=5000)\n",
    "    m.fit(X_scaled[idx], y.iloc[idx])\n",
    "    boot_r2.append(r2_score(y.iloc[idx], m.predict(X_scaled[idx])))\n",
    "    for j, f in enumerate(final_features):\n",
    "        if abs(m.coef_[j]) > THRESH:\n",
    "            selection_count[f] += 1\n",
    "\n",
    "boot_r2 = np.array(boot_r2)\n",
    "print(f\"Bootstrap R² 95% CI: [{np.percentile(boot_r2, 2.5):.3f}, {np.percentile(boot_r2, 97.5):.3f}]\")\n",
    "\n",
    "cv_scores = cross_val_score(model, X_scaled, y, cv=10, scoring='r2')\n",
    "print(f\"CV R² = {cv_scores.mean():.3f} ± {cv_scores.std():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Feature stability (|β|>{THRESH}):\")\n",
    "stability = pd.DataFrame([{'feature': f, 'freq': c/n_boot} for f, c in selection_count.items()])\n",
    "stability = stability.sort_values('freq', ascending=False)\n",
    "for _, row in stability.iterrows():\n",
    "    mark = \"*\" if row['freq'] >= 0.80 else \"\"\n",
    "    print(f\"  {row['feature']:45s} {row['freq']*100:5.1f}% {mark}\")\n",
    "print(f\"\\nFeatures ≥80%: {sum(stability['freq']>=0.80)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group-Specific Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "native = df['Primary_Language'] == 0\n",
    "nonnative = df['Primary_Language'] == 1\n",
    "\n",
    "t, p_val = stats.ttest_ind(df.loc[native, target], df.loc[nonnative, target])\n",
    "print(f\"Native: M={df.loc[native, target].mean():.2f}, SD={df.loc[native, target].std():.2f}\")\n",
    "print(f\"Non-native: M={df.loc[nonnative, target].mean():.2f}, SD={df.loc[nonnative, target].std():.2f}\")\n",
    "print(f\"t({len(df)-2})={t:.3f}, p={p_val:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Native model (top 6 features)\n",
    "native_df = df[native]\n",
    "y_n = native_df[target]\n",
    "corrs_n = [(f, abs(native_df[f].corr(y_n))) for f in ost_features]\n",
    "corrs_n.sort(key=lambda x: x[1], reverse=True)\n",
    "native_feats = [f for f, _ in corrs_n[:6]]\n",
    "\n",
    "X_n = StandardScaler().fit_transform(native_df[native_feats])\n",
    "m_n = ElasticNetCV(l1_ratio=[0.1,0.3,0.5,0.7,0.9], alphas=np.logspace(-2,1,20), cv=5, max_iter=5000, random_state=42)\n",
    "m_n.fit(X_n, y_n)\n",
    "\n",
    "r2_n = r2_score(y_n, m_n.predict(X_n))\n",
    "adj_r2_n = 1 - (1 - r2_n) * (len(y_n) - 1) / (len(y_n) - 6 - 1)\n",
    "\n",
    "print(f\"Native: n={len(y_n)}, k=6, R²={r2_n:.3f}, Adj R²={adj_r2_n:.3f}\")\n",
    "for f, c in sorted(zip(native_feats, m_n.coef_), key=lambda x: abs(x[1]), reverse=True):\n",
    "    print(f\"  {f:40s} β={c:+.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-native model (3 features)\n",
    "nn_feats = ['OST_flesch_kincaid_grade_level', 'OST_context_sensitive_count', 'OST_error_count']\n",
    "nn_df = df[nonnative]\n",
    "y_nn = nn_df[target]\n",
    "\n",
    "X_nn = StandardScaler().fit_transform(nn_df[nn_feats])\n",
    "m_nn = ElasticNetCV(l1_ratio=[0.1,0.3,0.5,0.7,0.9], alphas=np.logspace(-2,1,20), cv=5, max_iter=5000, random_state=42)\n",
    "m_nn.fit(X_nn, y_nn)\n",
    "\n",
    "r2_nn = r2_score(y_nn, m_nn.predict(X_nn))\n",
    "adj_r2_nn = 1 - (1 - r2_nn) * (len(y_nn) - 1) / (len(y_nn) - 3 - 1)\n",
    "\n",
    "print(f\"Non-native: n={len(y_nn)}, k=3, R²={r2_nn:.3f}, Adj R²={adj_r2_nn:.3f}\")\n",
    "for f, c in sorted(zip(nn_feats, m_nn.coef_), key=lambda x: abs(x[1]), reverse=True):\n",
    "    print(f\"  {f:40s} β={c:+.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 1: Feature Importance and Bootstrap Stability\n",
    "coef_plot = coef_df.sort_values('coef', key=abs, ascending=True)\n",
    "stab_plot = stability.sort_values('freq', ascending=True)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "ax1 = axes[0]\n",
    "colors1 = ['#2ecc71' if c > 0 else '#e74c3c' for c in coef_plot['coef']]\n",
    "ax1.barh(range(len(coef_plot)), coef_plot['coef'], color=colors1, alpha=0.85)\n",
    "ax1.set_yticks(range(len(coef_plot)))\n",
    "ax1.set_yticklabels([f.replace('OST_', '').replace('_', ' ') for f in coef_plot['feature']], fontsize=10)\n",
    "ax1.axvline(0, color='black', lw=0.8)\n",
    "ax1.set_xlabel('Standardized Coefficient (β)')\n",
    "ax1.set_title('(A) Feature Importance', fontweight='bold')\n",
    "ax1.spines['top'].set_visible(False)\n",
    "ax1.spines['right'].set_visible(False)\n",
    "\n",
    "ax2 = axes[1]\n",
    "ax2.barh(range(len(stab_plot)), stab_plot['freq'], color='#3498db', alpha=0.85)\n",
    "ax2.set_yticks(range(len(stab_plot)))\n",
    "ax2.set_yticklabels([f.replace('OST_', '').replace('_', ' ') for f in stab_plot['feature']], fontsize=10)\n",
    "ax2.axvline(0.8, color='#e74c3c', ls='--', lw=2, label='80% threshold')\n",
    "ax2.set_xlabel('Selection Frequency')\n",
    "ax2.set_title('(B) Bootstrap Stability (1,000 iterations)', fontweight='bold')\n",
    "ax2.set_xlim(0, 1.05)\n",
    "ax2.legend(loc='lower right')\n",
    "ax2.spines['top'].set_visible(False)\n",
    "ax2.spines['right'].set_visible(False)\n",
    "for i, (_, row) in enumerate(stab_plot.iterrows()):\n",
    "    ax2.text(row['freq']+0.02, i, f\"{row['freq']*100:.0f}%\", va='center', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('Figure1_Feature_Importance_Stability.png', dpi=300, bbox_inches='tight')\n",
    "plt.savefig('Figure1_Feature_Importance_Stability.pdf', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 2: Group-Specific Feature Coefficients\n",
    "native_coefs = pd.DataFrame({'feature': native_feats, 'coef': m_n.coef_}).sort_values('coef', key=abs, ascending=True)\n",
    "nn_coefs = pd.DataFrame({'feature': nn_feats, 'coef': m_nn.coef_}).sort_values('coef', key=abs, ascending=True)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "ax1 = axes[0]\n",
    "c1 = ['#4CAF50' if c > 0 else '#F44336' for c in native_coefs['coef']]\n",
    "ax1.barh(range(len(native_coefs)), native_coefs['coef'], color=c1, height=0.65)\n",
    "ax1.set_yticks(range(len(native_coefs)))\n",
    "ax1.set_yticklabels([f.replace('OST_', '').replace('_', '_') for f in native_coefs['feature']], fontsize=10)\n",
    "ax1.axvline(0, color='black', lw=0.8)\n",
    "ax1.set_xlabel('Standardized Coefficient')\n",
    "ax1.set_title(f'Native Speakers (n={len(y_n)}, 6 features)\\nR²={r2_n:.3f}, Adj R²={adj_r2_n:.3f}')\n",
    "ax1.spines['top'].set_visible(False)\n",
    "ax1.spines['right'].set_visible(False)\n",
    "\n",
    "ax2 = axes[1]\n",
    "c2 = ['#4CAF50' if c > 0 else '#F44336' for c in nn_coefs['coef']]\n",
    "ax2.barh(range(len(nn_coefs)), nn_coefs['coef'], color=c2, height=0.65)\n",
    "ax2.set_yticks(range(len(nn_coefs)))\n",
    "ax2.set_yticklabels([f.replace('OST_', '').replace('_', '_') for f in nn_coefs['feature']], fontsize=10)\n",
    "ax2.axvline(0, color='black', lw=0.8)\n",
    "ax2.set_xlabel('Standardized Coefficient')\n",
    "ax2.set_title(f'Non-Native Speakers (n={len(y_nn)}, 3 features)\\nR²={r2_nn:.3f}, Adj R²={adj_r2_nn:.3f}')\n",
    "ax2.spines['top'].set_visible(False)\n",
    "ax2.spines['right'].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('Figure2_Group_Coefficients.png', dpi=300, bbox_inches='tight')\n",
    "plt.savefig('Figure2_Group_Coefficients.pdf', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\"\"\n",
    "FULL MODEL (N={n}):\n",
    "  Features: {p}\n",
    "  R²={r2:.3f}, Adj R²={adj_r2:.3f}\n",
    "  Bootstrap R² 95% CI: [{np.percentile(boot_r2, 2.5):.3f}, {np.percentile(boot_r2, 97.5):.3f}]\n",
    "  CV R²={cv_scores.mean():.3f}±{cv_scores.std():.3f}\n",
    "  Stable features (≥80%): {sum(stability['freq']>=0.80)}\n",
    "\n",
    "GROUP-SPECIFIC:\n",
    "  Native (n={len(y_n)}): 6 features, R²={r2_n:.3f}, Adj R²={adj_r2_n:.3f}\n",
    "  Non-native (n={len(y_nn)}): 3 features, R²={r2_nn:.3f}, Adj R²={adj_r2_nn:.3f}\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
